{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4acf4161-bd15-41fb-9705-ce83453f62d0",
   "metadata": {},
   "source": [
    "# Day 1: Tensors in Machine Learning\n",
    "\n",
    "Tensors are the fundamental building blocks in many machine learning libraries like TensorFlow and PyTorch. They're essentially multi-dimensional arrays, and understanding them lays the groundwork for understanding how data flows through neural networks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e09591-55af-4ac0-87bb-8f3487afd4d8",
   "metadata": {},
   "source": [
    "### First import the numpy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b97ce6-9fa1-4e76-b5a4-dbce46494b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af4374d-6d3b-41b0-9225-cb18605d815e",
   "metadata": {},
   "source": [
    "### 0-D Tensors (Scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e17ace9-ea1e-4763-9fc2-d88d6f6fdf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Dimension: 0\n",
      "Shape: ()\n"
     ]
    }
   ],
   "source": [
    "a = np.array(5)\n",
    "print(a)\n",
    "print(f\"Dimension: {a.ndim}\")\n",
    "print(f\"Shape: {a.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e09e52-d79a-4b8e-a4cd-f3a332c5ef84",
   "metadata": {},
   "source": [
    "A scalar has no axis — it's just a single number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e4db47-a734-497a-be96-765f44d6397a",
   "metadata": {},
   "source": [
    "### 1-D Tensors (Vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dcd42e08-26e1-463a-be24-f874d3e538c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 7 9]\n",
      "\n",
      "Dimension: {b.ndim}\n",
      "Shape: (3,)\n"
     ]
    }
   ],
   "source": [
    "b = np.array([3, 7, 9])\n",
    "print(b)\n",
    "print(\"Dimension: {b.ndim}\")\n",
    "print(f\"Shape: {b.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d9472-90ca-4c43-89e1-42852417fe01",
   "metadata": {},
   "source": [
    "Vectors are 1D arrays. They're often used to represent features or weights in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98956252-8b34-49bf-9f64-9697137a34dc",
   "metadata": {},
   "source": [
    "### 2-D Tensors (Matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "601ada7b-af58-4f9e-9c25-1ee611db5aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "Dimension: 2\n",
      "Shape: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "c = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(c)\n",
    "print(f\"Dimension: {c.ndim}\")\n",
    "print(f\"Shape: {c.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab021e-ba3b-4f53-8059-3efe4296237d",
   "metadata": {},
   "source": [
    "Matrices (2D tensors) are used in data tables, grayscale images, and weight matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c4ab2-6225-4664-9f5f-b38bea5cdd4f",
   "metadata": {},
   "source": [
    "### 3-D Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db599d6a-012a-4a84-94fb-13eab83cbd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n",
      "Dimension: 3\n",
      "Shape: (2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(d)\n",
    "print(f\"Dimension: {d.ndim}\")\n",
    "print(f\"Shape: {d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d702de9-f873-4764-8b20-99050cf8cf38",
   "metadata": {},
   "source": [
    "Think of this as a stack of matrices. Commonly used in colored image data:\n",
    "\n",
    "- RGB images: `(height, width, 3 channels)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c1194-33e0-4710-860c-7198818709eb",
   "metadata": {},
   "source": [
    "### 4-D Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcb908dc-d406-4743-bcee-a60d96b87bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1  2]\n",
      "   [ 3  4]]\n",
      "\n",
      "  [[ 5  6]\n",
      "   [ 7  8]]]\n",
      "\n",
      "\n",
      " [[[ 9 10]\n",
      "   [11 12]]\n",
      "\n",
      "  [[13 14]\n",
      "   [15 16]]]]\n",
      "Dimension: 4\n",
      "Shape: (2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "e = np.array([[[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n",
    "              [[[9, 10], [11, 12]], [[13, 14], [15, 16]]]])\n",
    "print(e)\n",
    "print(f\"Dimension: {e.ndim}\")\n",
    "print(f\"Shape: {e.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaf71d2-c152-4ccf-934b-2ff5fbfbf4a3",
   "metadata": {},
   "source": [
    "Used for batches of RGB images:\n",
    "\n",
    "- `(batch_size, height, width, channels)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c0ab6-79e9-46bd-be16-a9440f491121",
   "metadata": {},
   "source": [
    "### 5️⃣–7️⃣ N-D Tensors\n",
    "Continue the pattern..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d26ad6-727e-4fe4-b1f8-f24f5a6d8c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array([...])  # 5D\n",
    "g = np.array([...])  # 6D\n",
    "h = np.array([...])  # 7D\n",
    "\n",
    "# Print their ndim and shape similarly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d009a34b-145b-432f-aacb-8a5ceab3eabd",
   "metadata": {},
   "source": [
    "The deeper you go, the more abstract — used in NLP, video data, volumetric scans, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174485a4-fd5a-459b-8be1-0abbd8c55b45",
   "metadata": {},
   "source": [
    "### 5-D Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bf7e518-c723-4c9d-9124-c8428c6270a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[ 1  2]\n",
      "    [ 3  4]]\n",
      "\n",
      "   [[ 5  6]\n",
      "    [ 7  8]]]\n",
      "\n",
      "\n",
      "  [[[ 9 10]\n",
      "    [11 12]]\n",
      "\n",
      "   [[13 14]\n",
      "    [15 16]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[17 18]\n",
      "    [19 20]]\n",
      "\n",
      "   [[21 22]\n",
      "    [23 24]]]\n",
      "\n",
      "\n",
      "  [[[25 26]\n",
      "    [27 28]]\n",
      "\n",
      "   [[29 30]\n",
      "    [31 32]]]]]\n",
      "Dimension: 5\n",
      "Shape: (2, 2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "f = np.array([\n",
    "    [\n",
    "        [ [[1, 2], [3, 4]], [[5, 6], [7, 8]] ],\n",
    "        [ [[9, 10], [11, 12]], [[13, 14], [15, 16]] ]\n",
    "    ],\n",
    "    [\n",
    "        [ [[17, 18], [19, 20]], [[21, 22], [23, 24]] ],\n",
    "        [ [[25, 26], [27, 28]], [[29, 30], [31, 32]] ]\n",
    "    ]\n",
    "])\n",
    "print(f)\n",
    "print(f\"Dimension: {f.ndim}\")\n",
    "print(f\"Shape: {f.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76caee25-9c81-4116-9e37-d163b2a8a235",
   "metadata": {},
   "source": [
    "#### Interpretation:\n",
    "This 5D tensor can be interpreted as:\n",
    "\n",
    "**(batch_size=2, time=2, height=2, width=2, channels=2)**\n",
    "\n",
    "#### Real-world usage:\n",
    "\n",
    "- Video classification with grayscale images over time.\n",
    "- 3D volumetric data (like CT scans) where depth adds another dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9546b4db-5616-43a6-9b8a-2b7a5df8b7b6",
   "metadata": {},
   "source": [
    "### 6-D Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3b46033-aa92-4c5b-8378-1c6fd843a419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[[ 1  2]\n",
      "     [ 3  4]]\n",
      "\n",
      "    [[ 5  6]\n",
      "     [ 7  8]]]\n",
      "\n",
      "\n",
      "   [[[ 9 10]\n",
      "     [11 12]]\n",
      "\n",
      "    [[13 14]\n",
      "     [15 16]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[17 18]\n",
      "     [19 20]]\n",
      "\n",
      "    [[21 22]\n",
      "     [23 24]]]\n",
      "\n",
      "\n",
      "   [[[25 26]\n",
      "     [27 28]]\n",
      "\n",
      "    [[29 30]\n",
      "     [31 32]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[ 1  2]\n",
      "     [ 3  4]]\n",
      "\n",
      "    [[ 5  6]\n",
      "     [ 7  8]]]\n",
      "\n",
      "\n",
      "   [[[ 9 10]\n",
      "     [11 12]]\n",
      "\n",
      "    [[13 14]\n",
      "     [15 16]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[17 18]\n",
      "     [19 20]]\n",
      "\n",
      "    [[21 22]\n",
      "     [23 24]]]\n",
      "\n",
      "\n",
      "   [[[25 26]\n",
      "     [27 28]]\n",
      "\n",
      "    [[29 30]\n",
      "     [31 32]]]]]]\n",
      "Dimension: 6\n",
      "Shape: (2, 2, 2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "g = np.array([\n",
    "    [\n",
    "        [\n",
    "            [[ [1, 2], [3, 4] ], [ [5, 6], [7, 8] ]],\n",
    "            [[ [9, 10], [11, 12] ], [ [13, 14], [15, 16] ]]\n",
    "        ],\n",
    "        [\n",
    "            [[ [17, 18], [19, 20] ], [ [21, 22], [23, 24] ]],\n",
    "            [[ [25, 26], [27, 28] ], [ [29, 30], [31, 32] ]]\n",
    "        ]\n",
    "    ],\n",
    "    [\n",
    "        [\n",
    "            [[ [1, 2], [3, 4] ], [ [5, 6], [7, 8] ]],\n",
    "            [[ [9, 10], [11, 12] ], [ [13, 14], [15, 16] ]]\n",
    "        ],\n",
    "        [\n",
    "            [[ [17, 18], [19, 20] ], [ [21, 22], [23, 24] ]],\n",
    "            [[ [25, 26], [27, 28] ], [ [29, 30], [31, 32] ]]\n",
    "        ]\n",
    "    ]\n",
    "])\n",
    "print(g)\n",
    "print(f\"Dimension: {g.ndim}\")\n",
    "print(f\"Shape: {g.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5304792-ce24-4eb6-b71a-a596654286d8",
   "metadata": {},
   "source": [
    "#### Interpretation:\n",
    "\n",
    "(batch_size=2, video_frames=2, time_steps=2, height=2, width=2, channels=2)\n",
    "\n",
    "#### Real-world usage:\n",
    "\n",
    "- Multi-camera video processing\n",
    "- Time-series of 3D volumes\n",
    "- Batch of MRI scans over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77b8efe-e6fe-4e3b-a6a8-2276375bfe3b",
   "metadata": {},
   "source": [
    "### 7-D Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e10749d-6c3a-4bbb-a220-69abff629165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[[[ 1  2]\n",
      "      [ 3  4]]\n",
      "\n",
      "     [[ 5  6]\n",
      "      [ 7  8]]]\n",
      "\n",
      "\n",
      "    [[[ 9 10]\n",
      "      [11 12]]\n",
      "\n",
      "     [[13 14]\n",
      "      [15 16]]]]\n",
      "\n",
      "\n",
      "\n",
      "   [[[[17 18]\n",
      "      [19 20]]\n",
      "\n",
      "     [[21 22]\n",
      "      [23 24]]]\n",
      "\n",
      "\n",
      "    [[[25 26]\n",
      "      [27 28]]\n",
      "\n",
      "     [[29 30]\n",
      "      [31 32]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  [[[[[ 1  2]\n",
      "      [ 3  4]]\n",
      "\n",
      "     [[ 5  6]\n",
      "      [ 7  8]]]\n",
      "\n",
      "\n",
      "    [[[ 9 10]\n",
      "      [11 12]]\n",
      "\n",
      "     [[13 14]\n",
      "      [15 16]]]]\n",
      "\n",
      "\n",
      "\n",
      "   [[[[17 18]\n",
      "      [19 20]]\n",
      "\n",
      "     [[21 22]\n",
      "      [23 24]]]\n",
      "\n",
      "\n",
      "    [[[25 26]\n",
      "      [27 28]]\n",
      "\n",
      "     [[29 30]\n",
      "      [31 32]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  [[[[[ 1  2]\n",
      "      [ 3  4]]\n",
      "\n",
      "     [[ 5  6]\n",
      "      [ 7  8]]]\n",
      "\n",
      "\n",
      "    [[[ 9 10]\n",
      "      [11 12]]\n",
      "\n",
      "     [[13 14]\n",
      "      [15 16]]]]\n",
      "\n",
      "\n",
      "\n",
      "   [[[[17 18]\n",
      "      [19 20]]\n",
      "\n",
      "     [[21 22]\n",
      "      [23 24]]]\n",
      "\n",
      "\n",
      "    [[[25 26]\n",
      "      [27 28]]\n",
      "\n",
      "     [[29 30]\n",
      "      [31 32]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  [[[[[ 1  2]\n",
      "      [ 3  4]]\n",
      "\n",
      "     [[ 5  6]\n",
      "      [ 7  8]]]\n",
      "\n",
      "\n",
      "    [[[ 9 10]\n",
      "      [11 12]]\n",
      "\n",
      "     [[13 14]\n",
      "      [15 16]]]]\n",
      "\n",
      "\n",
      "\n",
      "   [[[[17 18]\n",
      "      [19 20]]\n",
      "\n",
      "     [[21 22]\n",
      "      [23 24]]]\n",
      "\n",
      "\n",
      "    [[[25 26]\n",
      "      [27 28]]\n",
      "\n",
      "     [[29 30]\n",
      "      [31 32]]]]]]]\n",
      "\n",
      "Shape: (1, 4, 2, 2, 2, 2, 2)\n",
      "Dimensions: 7\n"
     ]
    }
   ],
   "source": [
    "h = np.array([\n",
    "    [\n",
    "    [  # 1st group\n",
    "        [  # 1st sub-group\n",
    "            [  # 1st block\n",
    "                [[1, 2], [3, 4]],\n",
    "                [[5, 6], [7, 8]]\n",
    "            ],\n",
    "            [\n",
    "                [[9, 10], [11, 12]],\n",
    "                [[13, 14], [15, 16]]\n",
    "            ]\n",
    "        ],\n",
    "        [\n",
    "            [  # 2nd block\n",
    "                [[17, 18], [19, 20]],\n",
    "                [[21, 22], [23, 24]]\n",
    "            ],\n",
    "            [\n",
    "                [[25, 26], [27, 28]],\n",
    "                [[29, 30], [31, 32]]\n",
    "            ]\n",
    "        ]\n",
    "    ],\n",
    "    [  # 2nd group\n",
    "        [  # 1st sub-group\n",
    "            [\n",
    "                [[1, 2], [3, 4]],\n",
    "                [[5, 6], [7, 8]]\n",
    "            ],\n",
    "            [\n",
    "                [[9, 10], [11, 12]],\n",
    "                [[13, 14], [15, 16]]\n",
    "            ]\n",
    "        ],\n",
    "        [\n",
    "            [\n",
    "                [[17, 18], [19, 20]],\n",
    "                [[21, 22], [23, 24]]\n",
    "            ],\n",
    "            [\n",
    "                [[25, 26], [27, 28]],\n",
    "                [[29, 30], [31, 32]]\n",
    "            ]\n",
    "        ]\n",
    "    ],\n",
    "    [  # 3rd group\n",
    "        [\n",
    "            [\n",
    "                [[1, 2], [3, 4]],\n",
    "                [[5, 6], [7, 8]]\n",
    "            ],\n",
    "            [\n",
    "                [[9, 10], [11, 12]],\n",
    "                [[13, 14], [15, 16]]\n",
    "            ]\n",
    "        ],\n",
    "        [\n",
    "            [\n",
    "                [[17, 18], [19, 20]],\n",
    "                [[21, 22], [23, 24]]\n",
    "            ],\n",
    "            [\n",
    "                [[25, 26], [27, 28]],\n",
    "                [[29, 30], [31, 32]]\n",
    "            ]\n",
    "        ]\n",
    "    ],\n",
    "    [  # 4th group\n",
    "        [\n",
    "            [\n",
    "                [[1, 2], [3, 4]],\n",
    "                [[5, 6], [7, 8]]\n",
    "            ],\n",
    "            [\n",
    "                [[9, 10], [11, 12]],\n",
    "                [[13, 14], [15, 16]]\n",
    "            ]\n",
    "        ],\n",
    "        [\n",
    "            [\n",
    "                [[17, 18], [19, 20]],\n",
    "                [[21, 22], [23, 24]]\n",
    "            ],\n",
    "            [\n",
    "                [[25, 26], [27, 28]],\n",
    "                [[29, 30], [31, 32]]\n",
    "            ]\n",
    "        ]\n",
    "    ]\n",
    "    ]    \n",
    "])\n",
    "print(h)\n",
    "print(\"\\nShape:\", h.shape)  # (1, 4, 2, 2, 2, 2, 2)\n",
    "print(\"Dimensions:\", h.ndim)  # 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d2c4e4-e4d8-4e38-a02c-238db360ba47",
   "metadata": {},
   "source": [
    "#### Interpretation:\n",
    "\n",
    "A hypothetical use case in deep learning for complex structured datasets like:\n",
    "- `(batch, group, time, camera, height, width, channels)`\n",
    "- Advanced recurrent spatio-temporal models in research\n",
    "\n",
    "#### Real-world usage:\n",
    "\n",
    "Rare in practice, but possible in:\n",
    "- Deep video understanding\n",
    "-Scientific simulations with nested dimensions\n",
    "- Tensor decomposition and multimodal learning (vision + audio + temporal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9658ce9a-3354-4266-a850-09dbf9bae554",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "| Tensor Dim | Meaning                         | Example Use                              |\n",
    "| ---------- | ------------------------------- | ---------------------------------------- |\n",
    "| 0-D        | Scalar                          | Single value                             |\n",
    "| 1-D        | Vector                          | Feature vector                           |\n",
    "| 2-D        | Matrix                          | Grayscale image, weight matrices         |\n",
    "| 3-D        | Stack of matrices               | RGB image, word embeddings               |\n",
    "| 4-D        | Batch of images                 | CNN inputs                               |\n",
    "| 5-D        | Batch of image sequences        | Videos, 3D data                          |\n",
    "| 6-D        | Sequences of volumetric data    | Medical imaging time-series              |\n",
    "| 7-D        | Complex nested sequence/volumes | Multimodal AI models, rare scientific ML |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
